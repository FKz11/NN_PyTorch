{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FKz11/NN_PyTorch/blob/main/lesson_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lesson-4"
      ],
      "metadata": {
        "id": "EkA6FCyP7S1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотеки:"
      ],
      "metadata": {
        "id": "kMPaGaoB7VYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CntGQdSk7VvS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Обучите CNN (самописная) на CIFAR-100."
      ],
      "metadata": {
        "id": "Rf1udQ4FQysq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных"
      ],
      "metadata": {
        "id": "U5mGqIFgvqX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR100(root='data/', \n",
        "                                 train=True, \n",
        "                                 transform=transforms.ToTensor(), \n",
        "                                 download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INqRaUKKRIUY",
        "outputId": "eb624c6c-ace1-47f2-fd4b-c3f7c6bd9f83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример изображения"
      ],
      "metadata": {
        "id": "Ehmc214MsbXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset[5]\n",
        "print(image.size())\n",
        "print(label)\n",
        "print(train_dataset.classes[label])\n",
        "plt.imshow(image.permute(1, 2, 0).numpy());"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "Nw4uZaGosb8j",
        "outputId": "81125448-9111-4be3-c799-581699ac11a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "86\n",
            "telephone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "kyEs9Axlvu9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=128, \n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)"
      ],
      "metadata": {
        "id": "REp6PtBYvxD5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', \n",
        "                                             train=False,\n",
        "                                             download=True, \n",
        "                                             transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                          batch_size=128,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgxGqgvRv0hE",
        "outputId": "349d0def-1a96-43ac-94bf-2b11d8f4e6e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Net"
      ],
      "metadata": {
        "id": "DJdQ-NXMwfTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, deep, hidden_channels, hidden_dim, dropout, negative_slope, glob_max_pool):\n",
        "        super(Net, self).__init__()\n",
        "        self.deep = deep\n",
        "        self.glob_max_pool = glob_max_pool\n",
        "\n",
        "        self.bn = nn.ModuleList()\n",
        "        self.conv = nn.ModuleList()\n",
        "\n",
        "        self.dp = nn.Dropout(dropout)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope)\n",
        "\n",
        "        self.conv.append(nn.Conv2d(3, hidden_channels, 3, padding=1))\n",
        "        self.bn.append(nn.BatchNorm2d(hidden_channels))\n",
        "        for i in range(deep-1): \n",
        "          self.conv.append(nn.Conv2d(hidden_channels*2**i, hidden_channels*2**(i+1), 3, stride=2, padding=1))\n",
        "          self.bn.append(nn.BatchNorm2d(hidden_channels*2**(i+1)))\n",
        "        if glob_max_pool:\n",
        "          first_dim = hidden_channels*2**(deep-1)\n",
        "        else:\n",
        "          first_dim = hidden_channels*2**(11-deep)\n",
        "        self.fc_1 = nn.Linear(first_dim, hidden_dim*2)\n",
        "        self.bn_1 = nn.BatchNorm1d(hidden_dim*2)\n",
        "        self.fc_2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.bn_2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc_3 = nn.Linear(hidden_dim, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        for i in range(self.deep):\n",
        "          x = self.conv[i](x)\n",
        "          x = self.bn[i](x)\n",
        "          x = self.lrelu(x)\n",
        "          x = self.dp(x)\n",
        "\n",
        "        if self.glob_max_pool:\n",
        "          x = F.max_pool2d(x, 2**(6-self.deep))\n",
        "          \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = self.fc_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.dp(x)\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.dp(x)\n",
        "\n",
        "        x = self.fc_3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "59IgrsNXwfrQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Net"
      ],
      "metadata": {
        "id": "wZOeom5-KEoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DSM2yDfbJ3NI",
        "outputId": "d730385e-0342-4174-8bf3-10a40535e89c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def net_train(net, train_loader, test_loader, num_epochs, lr, noise):\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "\n",
        "    for data in train_loader:\n",
        "\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      # Обнуляем градиент\n",
        "      optimizer.zero_grad()\n",
        "      # Делаем предсказание\n",
        "      outputs = net(inputs)\n",
        "      # Рассчитываем лосс-функцию\n",
        "      loss = criterion(outputs, labels)\n",
        "      # Делаем шаг назад по лоссу\n",
        "      loss.backward()\n",
        "      # Делаем шаг нашего оптимайзера\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    # Расчитываем loss на test\n",
        "    for data in test_loader:\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "    # Расчитываем acc на test\n",
        "      test_acc += (torch.max(outputs, 1)[1] == labels).sum().item() / len(labels)\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    if noise:\n",
        "      print(f'Epoch: {epoch + 1}; '\\\n",
        "            f'Train_loss: {round(train_loss / len(train_loader), 3)}; '\\\n",
        "            f'Test_loss: {round(test_loss / len(test_loader), 3)}; '\\\n",
        "            f'Test_acc: {round(test_acc / len(test_loader), 3)}')\n",
        "  \n",
        "  return net, round(test_acc / len(test_loader), 3)"
      ],
      "metadata": {
        "id": "0gUbzHsTKE6g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best model"
      ],
      "metadata": {
        "id": "fHymQUOo5Sb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(deep=5, hidden_channels=50, hidden_dim=100, dropout=0.0, negative_slope=0.2, glob_max_pool=False).to(device)\n",
        "print(net)\n",
        "summary(net.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZicLnHqHfBK",
        "outputId": "f8e25b3e-5ded-4817-8843-3f35200c9add"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (bn): ModuleList(\n",
            "    (0): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(50, 100, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (2): Conv2d(100, 200, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (3): Conv2d(200, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Conv2d(400, 800, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (dp): Dropout(p=0.0, inplace=False)\n",
            "  (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "  (fc_1): Linear(in_features=3200, out_features=200, bias=True)\n",
            "  (bn_1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc_2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (bn_2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc_3): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 50, 32, 32]           1,400\n",
            "       BatchNorm2d-2           [-1, 50, 32, 32]             100\n",
            "         LeakyReLU-3           [-1, 50, 32, 32]               0\n",
            "           Dropout-4           [-1, 50, 32, 32]               0\n",
            "            Conv2d-5          [-1, 100, 16, 16]          45,100\n",
            "       BatchNorm2d-6          [-1, 100, 16, 16]             200\n",
            "         LeakyReLU-7          [-1, 100, 16, 16]               0\n",
            "           Dropout-8          [-1, 100, 16, 16]               0\n",
            "            Conv2d-9            [-1, 200, 8, 8]         180,200\n",
            "      BatchNorm2d-10            [-1, 200, 8, 8]             400\n",
            "        LeakyReLU-11            [-1, 200, 8, 8]               0\n",
            "          Dropout-12            [-1, 200, 8, 8]               0\n",
            "           Conv2d-13            [-1, 400, 4, 4]         720,400\n",
            "      BatchNorm2d-14            [-1, 400, 4, 4]             800\n",
            "        LeakyReLU-15            [-1, 400, 4, 4]               0\n",
            "          Dropout-16            [-1, 400, 4, 4]               0\n",
            "           Conv2d-17            [-1, 800, 2, 2]       2,880,800\n",
            "      BatchNorm2d-18            [-1, 800, 2, 2]           1,600\n",
            "        LeakyReLU-19            [-1, 800, 2, 2]               0\n",
            "          Dropout-20            [-1, 800, 2, 2]               0\n",
            "           Linear-21                  [-1, 200]         640,200\n",
            "      BatchNorm1d-22                  [-1, 200]             400\n",
            "        LeakyReLU-23                  [-1, 200]               0\n",
            "          Dropout-24                  [-1, 200]               0\n",
            "           Linear-25                  [-1, 100]          20,100\n",
            "      BatchNorm1d-26                  [-1, 100]             200\n",
            "        LeakyReLU-27                  [-1, 100]               0\n",
            "          Dropout-28                  [-1, 100]               0\n",
            "           Linear-29                  [-1, 100]          10,100\n",
            "================================================================\n",
            "Total params: 4,502,000\n",
            "Trainable params: 4,502,000\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.04\n",
            "Params size (MB): 17.17\n",
            "Estimated Total Size (MB): 20.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "net = Net(deep=5, hidden_channels=50, hidden_dim=100, dropout=0.0, negative_slope=0.2, glob_max_pool=False).to(device)\n",
        "net.train()\n",
        "\n",
        "net, loss = net_train(net, train_loader, test_loader, num_epochs=20, lr=0.001, noise=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe9rB8Y8LVv2",
        "outputId": "af0f3f61-1303-4cf6-e991-8b1017c65860"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1; Train_loss: 3.555; Test_loss: 3.071; Test_acc: 0.249\n",
            "Epoch: 2; Train_loss: 2.744; Test_loss: 2.613; Test_acc: 0.334\n",
            "Epoch: 3; Train_loss: 2.309; Test_loss: 2.314; Test_acc: 0.393\n",
            "Epoch: 4; Train_loss: 2.0; Test_loss: 2.169; Test_acc: 0.425\n",
            "Epoch: 5; Train_loss: 1.75; Test_loss: 2.086; Test_acc: 0.444\n",
            "Epoch: 6; Train_loss: 1.506; Test_loss: 2.121; Test_acc: 0.446\n",
            "Epoch: 7; Train_loss: 1.256; Test_loss: 2.111; Test_acc: 0.468\n",
            "Epoch: 8; Train_loss: 1.007; Test_loss: 2.205; Test_acc: 0.457\n",
            "Epoch: 9; Train_loss: 0.775; Test_loss: 2.322; Test_acc: 0.459\n",
            "Epoch: 10; Train_loss: 0.568; Test_loss: 2.493; Test_acc: 0.454\n",
            "Epoch: 11; Train_loss: 0.398; Test_loss: 2.697; Test_acc: 0.449\n",
            "Epoch: 12; Train_loss: 0.282; Test_loss: 2.865; Test_acc: 0.446\n",
            "Epoch: 13; Train_loss: 0.225; Test_loss: 3.064; Test_acc: 0.441\n",
            "Epoch: 14; Train_loss: 0.188; Test_loss: 3.216; Test_acc: 0.439\n",
            "Epoch: 15; Train_loss: 0.184; Test_loss: 3.332; Test_acc: 0.439\n",
            "Epoch: 16; Train_loss: 0.164; Test_loss: 3.384; Test_acc: 0.451\n",
            "Epoch: 17; Train_loss: 0.132; Test_loss: 3.571; Test_acc: 0.436\n",
            "Epoch: 18; Train_loss: 0.121; Test_loss: 3.63; Test_acc: 0.44\n",
            "Epoch: 19; Train_loss: 0.115; Test_loss: 3.718; Test_acc: 0.44\n",
            "Epoch: 20; Train_loss: 0.133; Test_loss: 3.84; Test_acc: 0.428\n",
            "CPU times: user 4min, sys: 9.07 s, total: 4min 9s\n",
            "Wall time: 4min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50."
      ],
      "metadata": {
        "id": "pk_Pl63L5joq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "print(resnet50)\n",
        "summary(resnet50.to(device), input_size=(3, 256, 256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtn_usUu5ydW",
        "outputId": "e1ad90c1-723c-45d8-d19a-1bc6d12928a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "              ReLU-3         [-1, 64, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "              ReLU-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "             ReLU-10           [-1, 64, 64, 64]               0\n",
            "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
            "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
            "             ReLU-15          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
            "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
            "             ReLU-19           [-1, 64, 64, 64]               0\n",
            "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
            "             ReLU-22           [-1, 64, 64, 64]               0\n",
            "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
            "             ReLU-25          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
            "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
            "             ReLU-29           [-1, 64, 64, 64]               0\n",
            "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
            "             ReLU-32           [-1, 64, 64, 64]               0\n",
            "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
            "             ReLU-35          [-1, 256, 64, 64]               0\n",
            "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
            "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
            "             ReLU-39          [-1, 128, 64, 64]               0\n",
            "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
            "             ReLU-42          [-1, 128, 32, 32]               0\n",
            "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
            "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
            "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
            "             ReLU-51          [-1, 128, 32, 32]               0\n",
            "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
            "             ReLU-54          [-1, 128, 32, 32]               0\n",
            "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-57          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
            "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
            "             ReLU-61          [-1, 128, 32, 32]               0\n",
            "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
            "             ReLU-64          [-1, 128, 32, 32]               0\n",
            "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-67          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
            "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
            "             ReLU-71          [-1, 128, 32, 32]               0\n",
            "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
            "             ReLU-74          [-1, 128, 32, 32]               0\n",
            "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-77          [-1, 512, 32, 32]               0\n",
            "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
            "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
            "             ReLU-81          [-1, 256, 32, 32]               0\n",
            "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
            "             ReLU-84          [-1, 256, 16, 16]               0\n",
            "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
            "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-89         [-1, 1024, 16, 16]               0\n",
            "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
            "             ReLU-93          [-1, 256, 16, 16]               0\n",
            "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
            "             ReLU-96          [-1, 256, 16, 16]               0\n",
            "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-99         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
            "            ReLU-103          [-1, 256, 16, 16]               0\n",
            "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
            "            ReLU-106          [-1, 256, 16, 16]               0\n",
            "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-109         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
            "            ReLU-113          [-1, 256, 16, 16]               0\n",
            "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
            "            ReLU-116          [-1, 256, 16, 16]               0\n",
            "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-119         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
            "            ReLU-123          [-1, 256, 16, 16]               0\n",
            "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
            "            ReLU-126          [-1, 256, 16, 16]               0\n",
            "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-129         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
            "            ReLU-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
            "            ReLU-136          [-1, 256, 16, 16]               0\n",
            "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-139         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-143          [-1, 512, 16, 16]               0\n",
            "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-146            [-1, 512, 8, 8]               0\n",
            "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-151           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-155            [-1, 512, 8, 8]               0\n",
            "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-158            [-1, 512, 8, 8]               0\n",
            "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-161           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-165            [-1, 512, 8, 8]               0\n",
            "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-168            [-1, 512, 8, 8]               0\n",
            "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-171           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 374.27\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 472.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Замораживаем предтренированную модель"
      ],
      "metadata": {
        "id": "oDHU5aBb7KDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "KjL3oL4i7Mhv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузим данные обработав их под предтренированную модель"
      ],
      "metadata": {
        "id": "CFrai9BGMOCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR100(root='data/', \n",
        "                                 train=True, \n",
        "                                 transform=transforms.Compose([transforms.Resize(256),\n",
        "                                                               transforms.ToTensor(),\n",
        "                                                               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                                    std=[0.229, 0.224, 0.225])]), \n",
        "                                 download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='data/', \n",
        "                                 train=False, \n",
        "                                 transform=transforms.Compose([transforms.Resize(256),\n",
        "                                                               transforms.ToTensor(),\n",
        "                                                               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                                    std=[0.229, 0.224, 0.225])]), \n",
        "                                 download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvlKv7Ri5Rn0",
        "outputId": "1675c391-c260-44c7-d586-69acf6bac6fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=128, \n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=128, \n",
        "                                           shuffle=False,\n",
        "                                          num_workers=1)"
      ],
      "metadata": {
        "id": "8xn9hVYoAgFs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Добавим к модели свой классификатор и обучим его"
      ],
      "metadata": {
        "id": "5Rf40ae5LFes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "resnet50.fc = nn.Sequential(nn.Linear(2048, 100))\n",
        "resnet50.train()\n",
        "\n",
        "net, loss = net_train(resnet50.to(device), train_loader, test_loader, num_epochs=3, lr=0.001, noise=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBRd_W2DZZdT",
        "outputId": "370fda6f-e905-4962-d751-7d533a019531"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1; Train_loss: 2.441; Test_loss: 1.837; Test_acc: 0.514\n",
            "Epoch: 2; Train_loss: 1.652; Test_loss: 1.686; Test_acc: 0.537\n",
            "Epoch: 3; Train_loss: 1.497; Test_loss: 1.61; Test_acc: 0.556\n",
            "CPU times: user 12min 15s, sys: 32.4 s, total: 12min 47s\n",
            "Wall time: 13min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Вывод"
      ],
      "metadata": {
        "id": "LeBQoQ40VLNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я написал свою сверточную сеть для задачи классификации данных CIFAR100.\n",
        "\n",
        "Я использовал устоявшийся блок свёртки: conv -> bn -> lrelu -> drop.\n",
        "\n",
        "Вместо Pool я использовал stride, чтобы облегчить модель.\n",
        "\n",
        "С каждой следующей свёрткой я уменьшал размер изображения вдвое с помощью stride(кроме первой свётки), но при этом увеличивал количество карт признаков вдвое.\n",
        "\n",
        "После выделения признаков скользящими окнами(свёртками), я использовал классификатор, предварительно выпряямив данные.\n",
        "\n",
        "В классификаторе использовал схожий блок: lin -> bn -> lrelu -> drop.\n",
        "\n",
        "\n",
        "Как оказалось, здесь dropout не помогает против переобучения, так как это уже делает BatchNorm, а просто замедляет обучение сети, поэтому его гиперпарамет 0.0\n",
        "\n",
        "GlobalMaxPool оказался хуже выпрямления данных(flatten), даже когда карты признаков имеют размер 2х2(при deep=5). Видимо, факт того, что где то нет сигнала, а не только что он где то есть, несёт достаточно информации для улучшения метрики.\n",
        "\n",
        "При обучении самописной модели, после 7 эпохи ошибка на тесте(test_loss) начинает расти, а метрика на тесте(test_acc) перестаёт меняться, хотя ошибка на train(loss_train) продолжает падать:\n",
        "\n",
        "- Это связано с тем, что модель всё дальше учится, но после 7 эпохи, она перестаёт менять своё мнение, какая картика к какому классу относится, поэтому test_acc практически перестаёт меняться. \n",
        "\n",
        "- Модель чтобы уменьшить loss_train начинает давать более уверенные ответы, поэтому продолжает уменьшаться loss_train.\n",
        "\n",
        "- Так как модель начинает давать более уверенные ответы на train, то и на test она начинает сильнее ошибаться, тоесть сами ответы не меняются, но модель начинает быть в них более уверенной и давать этим ответам большую вероятность(если смотреть уже после softmax), из-за этого увеличивается loss_test.\n",
        "\n",
        "Это всё можно обобщить и назвать как переобучение после 7 эпохи. Модель перестаёт находить общие зависимости и начинает затачиваться под train примеры.\n",
        "\n",
        "\n",
        "Дальше я использовал предобученную сеть resnet50. \n",
        "\n",
        "Для того, чтобы её коректно использовать, нужно подогнать свои данные под размер 256х256 и нормализвать их по 3 каналам со средним mean=[0.485, 0.456, 0.406] и со среднеквадратическим отклонением std=[0.229, 0.224, 0.225], так как все модели из torchvision.models были предобучены на ImageNet, где каждой картинке изменяли размер до 256х256, и данные имели именно такие статистические параметры.\n",
        "\n",
        "Так как модель предобучена, то свёрточные слои уже умеют выделять информативные признаки для классификации и нам остаётся только обучить сам классификатор. В моём случае я использовал просто 1 полносвязный слой со 2048 входами и со 100 выходами. \n",
        "\n",
        "Сеть работает заметно дольше самописной, так как она гораздо больше и происходит очень много вычеслений.\n",
        "\n",
        "Но уже после первой эпохи, метрика больше чем у самописной сети.\n",
        "\n",
        "При этом после трёх эпох test_loss опускается, значит переобучение не наступило и у модели еще есть куда обучаться. Так же был использован самый простой классификатор в виде одного полносвязного слоя.\n",
        "\n",
        "Значит гораздо лучше с точки зрения результата, неговоря уже о том, что обучать сеть из 25 млн параметров пришлось бы очень долго, использовать предобученные сети. Особенно это касается свёрточных сетей, так как выделяемые ею карты признаков более универсальны, а так же свёрточным сетям не важен входной размер изображения, что является еще одним плюсом в пользу использования предобученных свёрточных сетей."
      ],
      "metadata": {
        "id": "8DNqFFM7VV5s"
      }
    }
  ]
}